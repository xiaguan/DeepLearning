{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import autograd,gluon,nd,init\n",
    "from mxnet.gluon import data as gdata,loss as gloss,nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((1460, 81), (1459, 80))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,test_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n0   1          60       RL         65.0       WD        Normal     208500\n1   2          20       RL         80.0       WD        Normal     181500\n2   3          60       RL         68.0       WD        Normal     223500\n3   4          70       RL         60.0       WD       Abnorml     140000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0:4,[0,1,2,3,-3,-2,-1]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_data.drop(train_data[(train_data['GrLivArea'] > 4000) & (train_data['SalePrice']<200000)].index,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(1454, 81)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop(train_data[(train_data['LotArea'] > 100000) ].index,inplace=True)\n",
    "train_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_data.drop(train_data[(train_data['BsmtFinSF1'] > 5000) ].index,inplace=True)\n",
    "train_data.drop(train_data[(train_data['BsmtFinSF1'] > 1400) ].index,inplace=True)\n",
    "train_data.drop(train_data[(train_data['MasVnrArea'] > 1200) ].index,inplace=True)\n",
    "train_data.drop(train_data[(train_data['TotalBsmtSF'] > 5000) ].index,inplace=True)\n",
    "train_data.drop(train_data[(train_data['1stFlrSF'] > 4000) ].index,inplace=True)\n",
    "train_data.drop(train_data[(train_data['EnclosedPorch'] > 500) ].index,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "all_features = pd.concat((train_data.iloc[:,1:-1],test_data.iloc[:,1:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(2874, 328)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = pd.get_dummies(all_features,dummy_na=True)\n",
    "all_features.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "((1415, 328), (1459, 328), (1415, 1))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = nd.array(all_features[:n_train].values)\n",
    "test_features = nd.array(all_features[n_train:].values)\n",
    "train_labels = nd.array(train_data.SalePrice.values).reshape((-1,1))\n",
    "train_features.shape,test_features.shape,train_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "loss = gloss.L2Loss()\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential()\n",
    "    net.add(nn.Dense(300,activation='relu'),nn.Dense(1))\n",
    "    net.initialize()\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3820881\n"
     ]
    }
   ],
   "source": [
    "def log_rmse(net,features,labels):\n",
    "    clipped_preds = nd.clip(net(features),1,float('inf'))\n",
    "    rmse = nd.sqrt(2*loss(clipped_preds.log(),labels.log()).mean())\n",
    "    return rmse.asscalar()\n",
    "\n",
    "def test_rmse(y_hat,y):\n",
    "    rmse = nd.sqrt(y_hat,y).mean()\n",
    "    return rmse.asscalar()\n",
    "a = nd.array([1,2,3])\n",
    "b = nd.array([2,3,4])\n",
    "print(test_rmse(a,b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train(net,train_features,train_labels,test_features,test_lables,num_epochs,learning_rate,weight_decay,batch_size):\n",
    "    train_ls,test_ls = [],[]\n",
    "    train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features,train_labels),batch_size,shuffle=True)\n",
    "    trainer = gluon.Trainer(net.collect_params(),'adam',{'learning_rate':learning_rate,'wd':weight_decay})\n",
    "    for epoch in range(num_epochs):\n",
    "        for X,y in train_iter:\n",
    "            with autograd.record():\n",
    "                l = loss(net(X),y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "        train_ls.append(log_rmse(net,train_features,train_labels))\n",
    "        if test_lables is not None:\n",
    "            test_ls.append(log_rmse(net,test_features,test_lables))\n",
    "    return train_ls,test_ls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_k_fold_data(k,i,X,y):\n",
    "    assert k>1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train ,y_train = None,None\n",
    "    for j in range(k):\n",
    "        idx = slice(j*fold_size,(j+1)*fold_size)\n",
    "        X_part,y_part = X[idx,:],y[idx]\n",
    "        if j==i:\n",
    "            X_valid,y_valid = X_part,y_part\n",
    "        elif X_train is None:\n",
    "            X_train ,y_train = X_part,y_part\n",
    "        else:\n",
    "            X_train = nd.concat(X_train,X_part,dim = 0)\n",
    "            y_train = nd.concat(y_train,y_part,dim=0)\n",
    "    return X_train,y_train,X_valid,y_valid"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def k_fold(k,X_train,y_train,num_epochs,learning_rate,weight_decay,batch_size):\n",
    "    train_l_sum,valid_l_sum = 0,0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k,i,X_train,y_train)\n",
    "        net = get_net()\n",
    "        a,b,c,d = data\n",
    "        train_ls,valid_ls = train(net,*data,num_epochs,learning_rate,weight_decay,batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        d2l.semilogy(range(1,num_epochs+1),train_ls,'epochs','rmse',range(1,num_epochs+1),valid_ls,['train','valid'])\n",
    "        print('fold % d ,train rmse %f,valid rmse %f' % (i,train_ls[-1],valid_ls[-1]))\n",
    "    return train_l_sum/k,valid_l_sum/k"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-1b847862b073>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mbatch_size\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m80\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtrain_l\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalid_l\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mk_fold\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_features\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_labels\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'%d-fold validation: avg train rmse %f,avg valid rmse %f'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_l\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalid_l\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-17-07ad7cf30cfa>\u001B[0m in \u001B[0;36mk_fold\u001B[1;34m(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size)\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[0mnet\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_net\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m         \u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0md\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m         \u001B[0mtrain_ls\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalid_ls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlearning_rate\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mweight_decay\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m         \u001B[0mtrain_l_sum\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mtrain_ls\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m         \u001B[0mvalid_l_sum\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mvalid_ls\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-15-57df45185216>\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(net, train_features, train_labels, test_features, test_lables, num_epochs, learning_rate, weight_decay, batch_size)\u001B[0m\n\u001B[0;32m      6\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_iter\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecord\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m                 \u001B[0ml\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m             \u001B[0ml\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m             \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mJ:\\DataLearning\\conda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    469\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    470\u001B[0m         \u001B[1;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 471\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    472\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    473\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mJ:\\DataLearning\\conda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\nn\\basic_layers.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mblock\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_children\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     54\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mJ:\\DataLearning\\conda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    469\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    470\u001B[0m         \u001B[1;34m\"\"\"Calls forward. Only accepts positional arguments.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 471\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    472\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    473\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mJ:\\DataLearning\\conda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\block.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m    711\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_cached_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    712\u001B[0m                 \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mctx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reg_params\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 713\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhybrid_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    714\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    715\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSymbol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mJ:\\DataLearning\\conda\\envs\\gluon\\lib\\site-packages\\mxnet\\gluon\\nn\\basic_layers.py\u001B[0m in \u001B[0;36mhybrid_forward\u001B[1;34m(self, F, x, weight, bias)\u001B[0m\n\u001B[0;32m    205\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mhybrid_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    206\u001B[0m         act = F.FullyConnected(x, weight, bias, no_bias=bias is None, num_hidden=self._units,\n\u001B[1;32m--> 207\u001B[1;33m                                flatten=self._flatten, name='fwd')\n\u001B[0m\u001B[0;32m    208\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mact\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    209\u001B[0m             \u001B[0mact\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mact\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mact\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mJ:\\DataLearning\\conda\\envs\\gluon\\lib\\site-packages\\mxnet\\ndarray\\register.py\u001B[0m in \u001B[0;36mFullyConnected\u001B[1;34m(data, weight, bias, num_hidden, no_bias, flatten, out, name, **kwargs)\u001B[0m\n",
      "\u001B[1;32mJ:\\DataLearning\\conda\\envs\\gluon\\lib\\site-packages\\mxnet\\_ctypes\\ndarray.py\u001B[0m in \u001B[0;36m_imperative_invoke\u001B[1;34m(handle, ndargs, keys, vals, out)\u001B[0m\n\u001B[0;32m     90\u001B[0m         \u001B[0mc_str_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m         \u001B[0mc_str_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ms\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mvals\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 92\u001B[1;33m         ctypes.byref(out_stypes)))\n\u001B[0m\u001B[0;32m     93\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0moriginal_output\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "k,num_epochs,lr,weight_decay,batch_size = 5,100,1,0,80\n",
    "train_l,valid_l = k_fold(k,train_features,train_labels,num_epochs,lr,weight_decay,batch_size)\n",
    "print('%d-fold validation: avg train rmse %f,avg valid rmse %f' % (k,train_l,valid_l))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_and_pred(train_featrues,test_features,train_labels,test_data,num_epochs,lr,weight_decay,batch_size):\n",
    "    net = get_net()\n",
    "    train_ls,_=train(net,train_features,train_labels,None,None,num_epochs,lr,weight_decay,batch_size)\n",
    "    preds = net(test_features).asnumpy()\n",
    "    test_data['SalePrice'] = pd.Series(preds.reshape(1,-1)[0])\n",
    "    sumbmission = pd.concat([test_data['Id'],test_data['SalePrice']],axis=1)\n",
    "    sumbmission.to_csv('submission.csv',index=False)\n",
    "train_and_pred(train_features,test_features,train_labels,test_data,num_epochs,lr,weight_decay,batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}